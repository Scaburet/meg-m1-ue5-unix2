{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Formation RNAseq CEA - juin 2024\n",
    "\n",
    "*Enseignantes: Sandrine Caburet et Claire Vandiedonck*\n",
    "\n",
    "Session IFB : 5 CPU + 21 GB de RAM\n",
    "\n",
    "# Part 6: Read Counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   \n",
    "\n",
    "- 0. 1 - About session for IFB core cluster\n",
    "- 0. 2 - Parameters to be set or modified by the user\n",
    "- 1 - Gene level quantification using ``featureCounts``\n",
    "- 2 - Pseudo-mapping with Salmon\n",
    "- 3 - Monitoring disk usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "- This notebook contains heavy running cells in Section 2, so make sure before you launch these cells that they are adapted to your environment. <br>\n",
    "For Samtools, the ``-m`` option is the **RAM memory size that will be used by each thread**! <br>\n",
    "<blockquote>\n",
    "        See options <code>--threads 3 -m 4G</code> in Samtools line, Section 2  <br>\n",
    "        Adapt <code>-T 4</code> in featureCounts lines to set it to 70-80% of available CPU number. <br>\n",
    "        Adapt <code>-s 0</code> in  line to fit your library preparation. In the current notebook version, this option is set to <code>0</code> as the librairies are unstranded. <br>\n",
    "</blockquote>\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "    <b>Values set in this notebook are valid for a 5-CPU session with access to 21 GB of RAM</b>. Ideally, use 70-80% of the CPU amount your system or session has. <br>\n",
    "    DO NOT ask for more RAM than you can use.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "## 0. Before going further\n",
    "---\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\"><b>Caution:</b> \n",
    "Before starting the analysis, save a backup copy of this notebok : in the left-hand panel, right-click on this file and select \"Duplicate\"<br>\n",
    "You can also make backups during the analysis. Don't forget to save your notebook regularly: <kbd>Ctrl</kbd> + <kbd>S</kbd> or click on the ðŸ’¾ icon.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 0.1 - About session for IFB core cluster\n",
    "\n",
    "<em>loaded JupyterLab</em> : Version 3.5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Cell launched on Mon Jun 24 12:00:40 CEST 2024 ===\n",
      "          40350384      fast sys/dash scaburet  R    2:38:33      1 cpu-node-51\n",
      "=== Current IFB session size: as an indication: Medium (4CPU, 10GB) or Large (10CPU, 50GB) ===\n",
      "JobID         AllocCPUS     ReqMem        NodeList    Elapsed      State \n",
      "------------ ---------- ---------- --------------- ---------- ---------- \n",
      "40350384              7        33G     cpu-node-51   02:38:33    RUNNING \n",
      "40350384.ba+          7                cpu-node-51   02:38:33    RUNNING \n"
     ]
    }
   ],
   "source": [
    "## Code cell 1 ##\n",
    "\n",
    "echo \"=== Cell launched on $(date) ===\"\n",
    "squeue -hu $USER \n",
    "\n",
    "echo \"=== Current IFB session size: as an indication: Medium (4CPU, 10GB) or Large (10CPU, 50GB) ===\"\n",
    "jobid=$(squeue -hu $USER | awk '/sys/dash {print $1}')\n",
    "\n",
    "sacct --format=JobID,AllocCPUS,ReqMem,NodeList,Elapsed,State --jobs ${jobid}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== bam sorting by names =====\n",
      "samtools 1.18\n",
      "Using htslib 1.19\n",
      "===== gene level quantification =====\n",
      "\n",
      "featureCounts v2.0.6\n",
      "\n",
      "===== Pseudo mapping and quantification with Salmon =====\n",
      "salmon 1.10.2\n",
      "===== quality reports compilation =====\n",
      "multiqc, version 1.13\n"
     ]
    }
   ],
   "source": [
    "## Code cell 2 ##\n",
    "\n",
    "module load samtools/1.18 subread/2.0.6 salmon/1.10.2 multiqc/1.13\n",
    "\n",
    "# module load samtools/1.10 subread/2.0.1 in 2023\n",
    "\n",
    "echo \"===== bam sorting by names =====\"\n",
    "samtools --version | head -n 2\n",
    "echo \"===== gene level quantification =====\"\n",
    "featureCounts -v\n",
    "echo \"===== Pseudo mapping and quantification with Salmon =====\"\n",
    "salmon -v\n",
    "echo \"===== quality reports compilation =====\"\n",
    "multiqc --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 0.2 - General parameters to be set or modified by the user\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Precise the **maximum amount of CPU** (central processing units, cores) and **RAM-memory (in Bytes)** that programs can use.<a id=\"computressources\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Code cell 3 ##\n",
    "\n",
    "authorizedCPU=5           # 4 CPU\n",
    "\n",
    "authorizedRAM=30000000000  # 20GB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Using a full path with a `/` at the end, **define the folder** where you want or have to work with `gohome` variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Home root folder is ===\n",
      "/shared/projects/2413_rnaseq_cea/\n",
      "\n",
      "=== Working (personal) folder tree ===\n",
      "/shared/projects/2413_rnaseq_cea/scaburet\n",
      "|-- Data\n",
      "|   |-- fastq\n",
      "|   `-- sra\n",
      "|-- Results\n",
      "|   |-- Rintro\n",
      "|   |-- deseq2\n",
      "|   |-- enrich\n",
      "|   |-- fastp\n",
      "|   |-- fastq_screen\n",
      "|   |-- fastqc\n",
      "|   |-- featurecounts\n",
      "|   |-- gsea\n",
      "|   |-- logfiles\n",
      "|   |-- multiqc\n",
      "|   |-- pca1\n",
      "|   |-- qualimap\n",
      "|   |-- qualimap-11juin\n",
      "|   |-- salmon\n",
      "|   |-- salmon2\n",
      "|   |-- samtools\n",
      "|   |-- samtools-11juin\n",
      "|   |-- star\n",
      "|   |-- star-11juin\n",
      "|   `-- wgcna\n",
      "|-- done\n",
      "|-- run_notebooks\n",
      "`-- stuff\n",
      "    `-- meg_m2_rnaseq\n",
      "\n",
      "28 directories\n",
      "=== current working directory ===\n",
      "/shared/ifbstor1/projects/2413_rnaseq_cea/scaburet\n"
     ]
    }
   ],
   "source": [
    "## Code cell 4 ##\n",
    "\n",
    "gohome=\"/shared/projects/2413_rnaseq_cea/\"\n",
    "\n",
    "echo \"=== Home root folder is ===\"\n",
    "echo \"${gohome}\"\n",
    "echo \"\"\n",
    "echo \"=== Working (personal) folder tree ===\"\n",
    "tree -d -L 2 \"${gohome}$USER\"\n",
    "echo \"=== current working directory ===\"\n",
    "echo \"${PWD}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ... and remember the folder for log files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the folder for log files is /shared/projects/2413_rnaseq_cea/scaburet/Results/logfiles/\n"
     ]
    }
   ],
   "source": [
    "## Code cell 5 ##\n",
    "\n",
    "logfolder=\"${gohome}$USER/Results/logfiles/\"\n",
    "echo \"the folder for log files is ${logfolder}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "## 1 - Gene level quantification using <code>featureCounts</code>\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1- Tool presentation\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`featureCounts` is part of the package <a href=\"http://subread.sourceforge.net/\">SubRead</a>, to be used with bash, and RSubRead, to be used with R. This tool allows to attribute mapped reads to their matching feature (exon, gene, promoter, ...) on the genome and summarize counts per feature.  \n",
    "  \n",
    "In SubRead user guide, developpers recommend to use <i>specialized transcript-level quantification tools [...] for counting reads to transcripts</i> (see section 6.2.5, page 34 of pdf manual you can download with this <a href=\"https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=&ved=2ahUKEwie1YDqwpD_AhXgU6QEHVLnB14QFnoECAsQAQ&url=https%3A%2F%2Fbioconductor.org%2Fpackages%2Frelease%2Fbioc%2Fvignettes%2FRsubread%2Finst%2Fdoc%2FSubreadUsersGuide.pdf&usg=AOvVaw1b3PpVhTNokdJHARtYAXgf\">link</a>). So we will only generate gene-level quantification with `featureCounts`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "featureCounts v2.0.6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Code cell 6 ##\n",
    "\n",
    "featureCounts -v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple usage to count paired-end sequencing data, then counts fragments instead or reads, is:  \n",
    "<code>featureCounts -p -a annotation.gtf \\ \n",
    "                  -o counts.txt \\ \n",
    "                  alignment.bam</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main <code>featureCounts</code> options correspond to: <br>\n",
    "- `-p` to count fragments instead or reads (paired-end data)\n",
    "- `-a TEXT` to locate annotation file, in GTF/GFF format by default (<code>-f</code> to be used to give other file format) that can be a <code>.gzip</code> one. <br>\n",
    "- `-o TEXT` to set filename for counts<br>\n",
    "- then alignement files (it may be a list) come. Either in BAM or SAM format, they can be sorted by read names or by chromosomal coordinates.\n",
    "- `M`: By default, multi-mapped reads (or fragments) are not considered unless we use `-M` option (see others parameters to set in manual, pdf pages 38 to 43).\n",
    "- `-T exon` *(by default)*: It will select exon lines in annotation file to attribute reads (or fragments).\n",
    "- `-g gene_id` *(by default)*: Then, it will count them according to gene_id meta-feature level."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use some other options:  \n",
    "\n",
    "- <code>-s INTEGER</code>, to specify strandness. Possible values include: 0 (unstranded), 1 (stranded) and 2 (reversely stranded). Default value is 0. <br>\n",
    "- <code>-T INTEGER</code>, to set the number of threads to use (default, 1) <br>\n",
    "- <code>--verbose</code>, to get information for debugging, such as unmatched chromosome/contig names. <br>\n",
    "    \n",
    "As temporary files are saved by default to directory specified in <code>-o</code> option, we won't use <code>--tmpDir STRING</code> option <br>\n",
    "</blockquote>\n",
    "\n",
    "For paired-end data, it is possible to ask for filtering fragments that have both ends aligned (`-B` option), on same chromose and strand (`-C`) and even separated by an insert distance (`-P`, included in `-d` and `-D` values).  \n",
    "\n",
    "Besides, input files will be used as sorted by names. Even if ***featureCount*** handles `.bam` files as fast as ***samtools*** does, we will nonetheless use samtools and `--donotsort` option. Indeed, some files may be bigger than supported by featureCounts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 1.2- Step preparation\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- With a `/` at the end, precise the folder where alignment ``_ALigned.SortedByCoord.out.bam`` files produced by ***Star*** are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3 bam files:\n",
      "/shared/projects/2413_rnaseq_cea/scaburet/Results/star/SRR12730409_Aligned.sortedByCoord.out.bam\n",
      "/shared/projects/2413_rnaseq_cea/scaburet/Results/star/SRR12730410_Aligned.sortedByCoord.out.bam\n",
      "/shared/projects/2413_rnaseq_cea/scaburet/Results/star/SRR12730411_Aligned.sortedByCoord.out.bam\n"
     ]
    }
   ],
   "source": [
    "## Code cell 7 ##\n",
    "\n",
    "mappedfolder=\"${gohome}$USER/Results/star/\"\n",
    "echo \"There are $(ls \"${mappedfolder}\"*_Aligned.sortedByCoord.out.bam | wc -l) bam files:\"\n",
    "ls \"${mappedfolder}\"*_Aligned.sortedByCoord.out.bam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Please remember the path to the uncompressed annotation file, especially if you changed it in previous notebooks. We can also show its first line to verify the version (here we work with the M35 release on the GRCm39 mouse genome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The transcript reference gtf file is /shared/projects/2413_rnaseq_cea/alldata/Reference/extracted/genome_annotation-M35.gtf\n",
      "First rows of the annotation file: /shared/projects/2413_rnaseq_cea/alldata/Reference/extracted/genome_annotation-M35.gtf\n",
      "##description: evidence-based annotation of the mouse genome (GRCm39), version M35 (Ensembl 112)\n",
      "##provider: GENCODE\n",
      "##contact: gencode-help@ebi.ac.uk\n",
      "##format: gtf\n",
      "##date: 2024-02-27\n",
      "chr1\tHAVANA\tgene\t3143476\t3144545\t.\t+\t.\tgene_id \"ENSMUSG00000102693.2\"; gene_type \"TEC\"; gene_name \"4933401J01Rik\"; level 2; mgi_id \"MGI:1918292\"; havana_gene \"OTTMUSG00000049935.1\";\n"
     ]
    }
   ],
   "source": [
    "## Code cell 8 ##\n",
    "\n",
    "gtffile=\"${gohome}alldata/Reference/extracted/genome_annotation-M35.gtf\"\n",
    "echo \"The transcript reference gtf file is ${gtffile}\"\n",
    "echo \"First rows of the annotation file: ${gtffile}\"\n",
    "head -n 6 ${gtffile}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We need to create a destination folder..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/shared/projects/2413_rnaseq_cea/scaburet/Results/\n",
      "|-- Rintro\n",
      "|-- deseq2\n",
      "|-- enrich\n",
      "|-- fastp\n",
      "|-- fastq_screen\n",
      "|-- fastqc\n",
      "|-- featurecounts\n",
      "|-- featurecounts2\n",
      "|-- gsea\n",
      "|-- logfiles\n",
      "|-- multiqc\n",
      "|-- pca1\n",
      "|-- qualimap\n",
      "|-- qualimap-11juin\n",
      "|-- salmon\n",
      "|-- salmon2\n",
      "|-- samtools\n",
      "|-- samtools-11juin\n",
      "|-- star\n",
      "|-- star-11juin\n",
      "`-- wgcna\n",
      "\n",
      "21 directories\n"
     ]
    }
   ],
   "source": [
    "## Code cell 9 ##\n",
    "\n",
    "featcountfolder=\"${gohome}$USER/Results/featurecounts2/\"\n",
    "mkdir -p ${featcountfolder}\n",
    "tree -d -L 1 \"${gohome}$USER/Results/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### 1.3- Compute reads or fragments counts\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.1 - Running <code>featuresCounts</code> on individual samples\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "- Before you run the following cells, make sure that they are adapted to your environment. <br>\n",
    "For Samtools, the ``-m`` option is the **RAM memory size that will be used by each thread**! <br>\n",
    "<blockquote>\n",
    "        See options <code>--threads 3 -m 5G</code> in Samtools line <br>\n",
    "        Adapt <code>-T 4</code> in featureCounts lines to set it to 70-80% of available CPU number. <br>\n",
    "        Adapt <code>-s 0</code> in  line to fit your library preparation. In the current notebook version, this option is set to <code>0</code> as the librairies are unstranded. <br>\n",
    "</blockquote>\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "    <b>Values set in this notebook are valid for a 5-CPU session with access to 21 GB of RAM</b>. Ideally, use 70-80% of the CPU amount your system or session has. <br>\n",
    "    DO NOT ask for more RAM than you can use.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <b><code>-T</code> option in featureCounts command line doesn't have an impact during counting process</b>. It has an effect when BAM are sorted on the fly by features counts, but this is not the case here, as the input file is sorted before by samtools.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Screen output is redirected to /shared/projects/2413_rnaseq_cea/scaburet/Results/logfiles/featureCounts-gene-level-counts-individualsamples_samtoolsSort-2.log\n"
     ]
    }
   ],
   "source": [
    "## Code cell 10 ##\n",
    "\n",
    "logfile=\"${logfolder}featureCounts-gene-level-counts-individualsamples_samtoolsSort-2.log\"\n",
    "echo \"Screen output is redirected to ${logfile}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell, each sample file is analysed individually: first <code>samtools</code> generates a bam sorted by read names, that is used immediately by <code>featureCounts</code>. The intermediate bam file is then removed.   \n",
    "Therefore we obtain one count file per sample. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Processing sampleID: SRR12730409...\n",
      "...changing tool...\n",
      "... done\n",
      "===== Processing sampleID: SRR12730410...\n",
      "...changing tool...\n",
      "... done\n",
      "===== Processing sampleID: SRR12730411...\n",
      "...changing tool...\n",
      "... done\n",
      "\n",
      "real\t12m40.250s\n",
      "user\t37m49.605s\n",
      "sys\t1m9.624s\n"
     ]
    }
   ],
   "source": [
    "## Code cell 11 ##\n",
    "\n",
    "# as time command does not redirect output\n",
    "echo \"operation starts at $(date)\" >> ${logfile}\n",
    "\n",
    "time for fn in $(ls \"${mappedfolder}\"*_Aligned.sortedByCoord.out.bam); do  \n",
    "    \n",
    "    mysortedbam=$(basename ${fn})\n",
    "    id=${mysortedbam/_Aligned.sortedByCoord.out.bam/}\n",
    "    echo \"===== Processing sampleID: ${id}...\" | tee -a ${logfile}\n",
    "    \n",
    "    # outputfiles\n",
    "    mytempfile=\"${featcountfolder}${id}_Aligned.sortedByNames.bam\"\n",
    "    myoutfile=\"${featcountfolder}${id}_paired-unstranded\"\n",
    "    \n",
    "    # bam sorting...\n",
    "    echo \"samtools starts at $(date)\" >> ${logfile}\n",
    "    samtools sort -n \\\n",
    "                --threads 3 -m 4G \\\n",
    "                --output-fmt BAM \\\n",
    "                -o ${mytempfile} \\\n",
    "                -T ${featcountfolder} \\\n",
    "                ${fn} \\\n",
    "                &>> ${logfile}\n",
    "    echo \"samtools ends at $(date)\" >> ${logfile}\n",
    "\n",
    "    # some user conversation to help being patient\n",
    "    echo \"...changing tool...\" | tee -a ${logfile}\n",
    "\n",
    "    # then featureCounts\n",
    "    echo \"featureCounts starts at $(date)\" >> ${logfile}\n",
    "\n",
    "    featureCounts -p -s 0 -T 4 \\\n",
    "                  -a \"${gtffile}\" \\\n",
    "                  -o \"${myoutfile}.counts\" \\\n",
    "                  ${mytempfile} \\\n",
    "                  --donotsort \\\n",
    "                  --verbose \\\n",
    "                  &>> ${logfile}\n",
    "    echo \"featureCounts ends at $(date)\" >> ${logfile}\n",
    "    \n",
    "    # removing extra bam file... saving disk space\n",
    "    rm ${mytempfile}\n",
    "    \n",
    "    echo \"... done\" | tee -a ${logfile}\n",
    "    \n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "featureCounts generated 3 count files.\n",
      "featureCounts generated 3 summary files.\n"
     ]
    }
   ],
   "source": [
    "## Code cell 12 ##\n",
    "\n",
    "echo \"operation ends at $(date)\" >> ${logfile}\n",
    "\n",
    "echo \"=== Files created after featureCounts ===\" >> ${logfile}\n",
    "ls -lh \"${featcountfolder}\" >> ${logfile}\n",
    "echo \"featureCounts generated $(ls \"${featcountfolder}\"*.counts | wc -l) count files.\" \\\n",
    "    | tee -a ${logfile}\n",
    "echo \"featureCounts generated $(ls \"${featcountfolder}\"*.counts.summary | wc -l) summary files.\" \\\n",
    "    | tee -a ${logfile}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.2 - Running <code>featuresCounts</code> on multiple samples\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above cell processed each sample file individually: each sorted bam generated by <code>samtools</code> is used as input by <code>featureCounts</code>, and we obtain one count file per sample. Those count files could be later joined in a single count matrix for the next step of analysis.   \n",
    "\n",
    "Alternatively, <code>featuresCounts</code> can handle multiple bam files at once, creating directly a single count matrix for all the samples.    \n",
    "This requires that all the sorted bam files are available as input for <code>featuresCounts</code>.    \n",
    "This was done beforehand for all 11 samples, by running the next 2 cells.   \n",
    "Code cell 14 runs <code>samtools</code> to generate (and keep!) the sorted bam files.   \n",
    "Code cell 16 runs <code>featuresCounts</code> only once, using the list of sorted bam filenames as input.  \n",
    "\n",
    "To run those cells in your own project, simply change their type from *Raw* to *Code*.\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## (Code cell 13) ##\n",
    "\n",
    "logfile2=\"${logfolder}featureCounts-gene-level-counts_3samplestogether-samtoolsSort.log\"\n",
    "echo \"Screen output is redirected to ${logfile2}\""
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## (Code cell 14) ##\n",
    "\n",
    "# as time command does not redirect output\n",
    "echo \"operation starts at $(date)\" >> ${logfile2}\n",
    "\n",
    "time for fn in $(ls \"${mappedfolder}\"*_Aligned.sortedByCoord.out.bam); do  \n",
    "    \n",
    "    mysortedbam=$(basename ${fn})\n",
    "    id=${mysortedbam/_Aligned.sortedByCoord.out.bam/}\n",
    "    echo \"===== Processing sampleID: ${id}...\" | tee -a ${logfile2}\n",
    "    \n",
    "    # outputfiles\n",
    "    mytempfile=\"${featcountfolder}${id}_Aligned.sortedByNames.bam\"\n",
    "\n",
    "    \n",
    "    # bam sorting...\n",
    "    echo \"samtools starts at $(date)\" >> ${logfile2}\n",
    "    samtools sort -n \\\n",
    "                --threads 3 -m 5G \\\n",
    "                --output-fmt BAM \\\n",
    "                -o ${mytempfile} \\\n",
    "                -T ${featcountfolder} \\\n",
    "                ${fn} \\\n",
    "                &>> ${logfile}\n",
    "    echo \"samtools ends at $(date)\" >> ${logfile2}\n",
    "\n",
    "done"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## (Code cell 15) ##\n",
    "# second log file for the featureCounts steps\n",
    "\n",
    "logfile3=\"${logfolder}counts-gene-level-counts-3samplestogether_featureCounts.log\"\n",
    "echo \"Screen output is redirected to ${logfile3}\""
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## (Code cell 16) ##\n",
    "\n",
    "# creating the list of input filenames\n",
    "listSortedBam=$(ls \"${featcountfolder}\"*_Aligned.sortedByNames.bam)\n",
    "echo \"The list of input files is: ${listSortedBam}\" | tee -a ${logfile3}\n",
    "\n",
    "myoutfile=\"${featcountfolder}3samples_paired-unstranded\"\n",
    "\n",
    "echo \"The output file is: ${myoutfile}\" | tee -a ${logfile3}\n",
    "\n",
    "# then running featureCounts\n",
    "echo \"featureCounts starts at $(date)\" >> ${logfile3}\n",
    "\n",
    "featureCounts -p -s 0 -T 16 \\\n",
    "              -a \"${gtffile}\" \\\n",
    "              -o \"${myoutfile}.counts\" \\\n",
    "              ${listSortedBam} \\\n",
    "              --donotsort \\\n",
    "              --verbose \\\n",
    "              &>> ${logfile3}\n",
    "echo \"featureCounts ends at $(date)\" >> ${logfile3}\n",
    "       \n",
    "echo \"... done\" | tee -a ${logfile3}\n",
    "echo \"operation ends at $(date)\" >> ${logfile3}\n",
    "\n",
    "echo \"=== Files created after featureCounts ===\" >> ${logfile3}\n",
    "ls -lh \"${featcountfolder}\" >> ${logfile3}\n",
    "echo \"featureCounts generated $(ls \"${featcountfolder}\"*.counts | wc -l) count files.\" \\\n",
    "    | tee -a ${logfile3}\n",
    "echo \"featureCounts generated $(ls \"${featcountfolder}\"*.counts.summary | wc -l) summary files.\" \\\n",
    "    | tee -a ${logfile3}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the proportions of alignements that match a single gene (if default `featureCounts` parameters were kept) in the logfile and a research for specified patterns (`grep -e PATTERN`)."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## Code cell 17 ##\n",
    "\n",
    "cat ${logfile3} | grep -e \"Successfully assigned alignments\" -e \"Process BAM\""
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## Code cell 18 ##\n",
    "\n",
    "# to have explanations\n",
    "echo \"summary file\"\n",
    "cat \"${myoutfile}.counts.summary\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the beginning of result files from featureCounts.   \n",
    "We retrieve a copy of the count for all samples in our own Results/featurecounts folder, and we display the two types of counts files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> /shared/projects/2413_rnaseq_cea/scaburet/Results/featurecounts/11samples_paired-unstranded.counts <==\n",
      "# Program:featureCounts v2.0.6; Command:\"featureCounts\" \"-p\" \"-s\" \"0\" \"-T\" \"16\" \"-a\" \"/shared/projects/2413_rnaseq_cea/alldata/Reference/extracted/genome_annotation-M35.gtf\" \"-o\" \"/shared/projects/2413_rnaseq_cea/alldata/Results/featurecounts/11samples_paired-unstranded.counts\" \"/shared/projects/2413_rnaseq_cea/alldata/Results/featurecounts/SRR12730403_Aligned.sortedByNames.bam\" \"/shared/projects/2413_rnaseq_cea/alldata/Results/featurecounts/SRR12730404_Aligned.sortedByNames.bam\" \"/shared/projects/2413_rnaseq_cea/alldata/Results/featurecounts/SRR12730405_Aligned.sortedByNames.bam\" \"/shared/projects/2413_rnaseq_cea/alldata/Results/featurecounts/SRR12730406_Aligned.sortedByNames.bam\" \"/shared/projects/2413_rnaseq_cea/alldata/Results/featurecounts/SRR12730407_Aligned.sortedByNames.bam\" \"/shared/projects/2413_rnaseq_cea/alldata/Results/featurecounts/SRR12730408_Aligned.sortedByNames.bam\" \"/shared/projects/2413_rnaseq_cea/alldata/Results/featurecounts/SRR12730409_Aligned.sortedByNames.bam\" \"/shared/projects/2413_rnaseq_cea/alldata/Results/featurecounts/SRR12730410_Aligned.sortedByNames.bam\" \"/shared/projects/2413_rnaseq_cea/alldata/Results/featurecounts/SRR12730411_Aligned.sortedByNames.bam\" \"/shared/projects/2413_rnaseq_cea/alldata/Results/featurecounts/SRR12730412_Aligned.sortedByNames.bam\" \"/shared/projects/2413_rnaseq_cea/alldata/Results/featurecounts/SRR12730413_Aligned.sortedByNames.bam\" \"--donotsort\" \"--verbose\" \n",
      "Geneid\tChr\tStart\tEnd\tStrand\tLength\t/shared/projects/2413_rnaseq_cea/alldata/Results/featurecounts/SRR12730403_Aligned.sortedByNames.bam\t/shared/projects/2413_rnaseq_cea/alldata/Results/featurecounts/SRR12730404_Aligned.sortedByNames.bam\t/shared/projects/2413_rnaseq_cea/alldata/Results/featurecounts/SRR12730405_Aligned.sortedByNames.bam\t/shared/projects/2413_rnaseq_cea/alldata/Results/featurecounts/SRR12730406_Aligned.sortedByNames.bam\t/shared/projects/2413_rnaseq_cea/alldata/Results/featurecounts/SRR12730407_Aligned.sortedByNames.bam\t/shared/projects/2413_rnaseq_cea/alldata/Results/featurecounts/SRR12730408_Aligned.sortedByNames.bam\t/shared/projects/2413_rnaseq_cea/alldata/Results/featurecounts/SRR12730409_Aligned.sortedByNames.bam\t/shared/projects/2413_rnaseq_cea/alldata/Results/featurecounts/SRR12730410_Aligned.sortedByNames.bam\t/shared/projects/2413_rnaseq_cea/alldata/Results/featurecounts/SRR12730411_Aligned.sortedByNames.bam\t/shared/projects/2413_rnaseq_cea/alldata/Results/featurecounts/SRR12730412_Aligned.sortedByNames.bam\t/shared/projects/2413_rnaseq_cea/alldata/Results/featurecounts/SRR12730413_Aligned.sortedByNames.bam\n",
      "ENSMUSG00000102693.2\tchr1\t3143476\t3144545\t+\t1070\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
      "ENSMUSG00000064842.3\tchr1\t3172239\t3172348\t+\t110\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
      "ENSMUSG00000051951.6\tchr1;chr1;chr1;chr1;chr1;chr1;chr1\t3276124;3276746;3283662;3283832;3284705;3491925;3740775\t3277540;3277540;3285855;3286567;3287191;3492124;3741721\t-;-;-;-;-;-;-\t6094\t0\t0\t0\t0\t0\t0\t0\t2\t0\t0\t0\n",
      "ENSMUSG00000102851.2\tchr1\t3322980\t3323459\t+\t480\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t1\n",
      "ENSMUSG00000103377.2\tchr1\t3435954\t3438772\t-\t2819\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
      "ENSMUSG00000104017.2\tchr1\t3445779\t3448011\t-\t2233\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
      "\n",
      "==> /shared/projects/2413_rnaseq_cea/scaburet/Results/featurecounts/SRR12730409_paired-unstranded.counts <==\n",
      "# Program:featureCounts v2.0.6; Command:\"featureCounts\" \"-p\" \"-s\" \"0\" \"-T\" \"16\" \"-a\" \"/shared/projects/2413_rnaseq_cea/alldata/Reference/extracted/genome_annotation-M35.gtf\" \"-o\" \"/shared/projects/2413_rnaseq_cea/scaburet/Results/featurecounts/SRR12730409_paired-unstranded.counts\" \"/shared/projects/2413_rnaseq_cea/scaburet/Results/featurecounts/SRR12730409_Aligned.sortedByNames.bam\" \"--donotsort\" \"--verbose\" \n",
      "Geneid\tChr\tStart\tEnd\tStrand\tLength\t/shared/projects/2413_rnaseq_cea/scaburet/Results/featurecounts/SRR12730409_Aligned.sortedByNames.bam\n",
      "ENSMUSG00000102693.2\tchr1\t3143476\t3144545\t+\t1070\t0\n",
      "ENSMUSG00000064842.3\tchr1\t3172239\t3172348\t+\t110\t0\n",
      "ENSMUSG00000051951.6\tchr1;chr1;chr1;chr1;chr1;chr1;chr1\t3276124;3276746;3283662;3283832;3284705;3491925;3740775\t3277540;3277540;3285855;3286567;3287191;3492124;3741721\t-;-;-;-;-;-;-\t6094\t0\n",
      "ENSMUSG00000102851.2\tchr1\t3322980\t3323459\t+\t480\t0\n",
      "ENSMUSG00000103377.2\tchr1\t3435954\t3438772\t-\t2819\t0\n",
      "ENSMUSG00000104017.2\tchr1\t3445779\t3448011\t-\t2233\t0\n",
      "\n",
      "==> /shared/projects/2413_rnaseq_cea/scaburet/Results/featurecounts/SRR12730410_paired-unstranded.counts <==\n",
      "# Program:featureCounts v2.0.6; Command:\"featureCounts\" \"-p\" \"-s\" \"0\" \"-T\" \"16\" \"-a\" \"/shared/projects/2413_rnaseq_cea/alldata/Reference/extracted/genome_annotation-M35.gtf\" \"-o\" \"/shared/projects/2413_rnaseq_cea/scaburet/Results/featurecounts/SRR12730410_paired-unstranded.counts\" \"/shared/projects/2413_rnaseq_cea/scaburet/Results/featurecounts/SRR12730410_Aligned.sortedByNames.bam\" \"--donotsort\" \"--verbose\" \n",
      "Geneid\tChr\tStart\tEnd\tStrand\tLength\t/shared/projects/2413_rnaseq_cea/scaburet/Results/featurecounts/SRR12730410_Aligned.sortedByNames.bam\n",
      "ENSMUSG00000102693.2\tchr1\t3143476\t3144545\t+\t1070\t0\n",
      "ENSMUSG00000064842.3\tchr1\t3172239\t3172348\t+\t110\t0\n",
      "ENSMUSG00000051951.6\tchr1;chr1;chr1;chr1;chr1;chr1;chr1\t3276124;3276746;3283662;3283832;3284705;3491925;3740775\t3277540;3277540;3285855;3286567;3287191;3492124;3741721\t-;-;-;-;-;-;-\t6094\t2\n",
      "ENSMUSG00000102851.2\tchr1\t3322980\t3323459\t+\t480\t0\n",
      "ENSMUSG00000103377.2\tchr1\t3435954\t3438772\t-\t2819\t0\n",
      "ENSMUSG00000104017.2\tchr1\t3445779\t3448011\t-\t2233\t0\n",
      "\n",
      "==> /shared/projects/2413_rnaseq_cea/scaburet/Results/featurecounts/SRR12730411_paired-unstranded.counts <==\n",
      "# Program:featureCounts v2.0.6; Command:\"featureCounts\" \"-p\" \"-s\" \"0\" \"-T\" \"16\" \"-a\" \"/shared/projects/2413_rnaseq_cea/alldata/Reference/extracted/genome_annotation-M35.gtf\" \"-o\" \"/shared/projects/2413_rnaseq_cea/scaburet/Results/featurecounts/SRR12730411_paired-unstranded.counts\" \"/shared/projects/2413_rnaseq_cea/scaburet/Results/featurecounts/SRR12730411_Aligned.sortedByNames.bam\" \"--donotsort\" \"--verbose\" \n",
      "Geneid\tChr\tStart\tEnd\tStrand\tLength\t/shared/projects/2413_rnaseq_cea/scaburet/Results/featurecounts/SRR12730411_Aligned.sortedByNames.bam\n",
      "ENSMUSG00000102693.2\tchr1\t3143476\t3144545\t+\t1070\t0\n",
      "ENSMUSG00000064842.3\tchr1\t3172239\t3172348\t+\t110\t0\n",
      "ENSMUSG00000051951.6\tchr1;chr1;chr1;chr1;chr1;chr1;chr1\t3276124;3276746;3283662;3283832;3284705;3491925;3740775\t3277540;3277540;3285855;3286567;3287191;3492124;3741721\t-;-;-;-;-;-;-\t6094\t0\n",
      "ENSMUSG00000102851.2\tchr1\t3322980\t3323459\t+\t480\t0\n",
      "ENSMUSG00000103377.2\tchr1\t3435954\t3438772\t-\t2819\t0\n",
      "ENSMUSG00000104017.2\tchr1\t3445779\t3448011\t-\t2233\t0\n"
     ]
    }
   ],
   "source": [
    "## Code cell 19 ##\n",
    "\n",
    "cp ${gohome}alldata/Results/featurecounts/11samples_* ${gohome}$USER/Results/featurecounts/\n",
    "\n",
    "head -n 8 ${gohome}$USER/Results/featurecounts/*_paired-unstranded.counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the genes are in rows and the counts in the samples are provided in the one-before-last column.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "---\n",
    "## 2 - Pseudo-mapping with **Salmon**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1- Tool presentation\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **pseudomapping** or **pseudoalignement** is an alternative method of counting reads to transcripts and genes without prior mapping to a reference genome. It relies on prior indexation of all transcripts (rather than indexing the genome). Using theses indeces, reads are directly assigned to transcripts. This method does not generate BAM/SAM alignement files. It produces directly the matrix of counts for each transcript.\n",
    "\n",
    "The main advantages of this method is the speed and direct count of all transcript isoforms (only annotated ones). On the opposite, only annotated transcripts can be counted and it does not allow the discovery of new transcripts. It is also impossible to vizualize the alignments of the reads with visualization tools such as IGV.\n",
    "To quantify expression at the gene level, transcript counts can simply be aggregated (i.e summed) by genes.\n",
    "\n",
    "Two softwares are currently available with very similar characteristics and outputs, namely [Salmon](https://salmon.readthedocs.io/en/latest/index.html#) and [Kallisto](https://pachterlab.github.io/kallisto/). You can find a brief summary of both methods here: https://learn.gencore.bio.nyu.edu/rna-seq-analysis/salmon-kallisto-rapid-transcript-quantification-for-rna-seq-data/. Both methods are higly similar and provide same results (see blog of Lior Pachter: https://liorpachter.wordpress.com/2015/05/10/near-optimal-rna-seq-quantification-with-kallisto/ claming that Salmon copied Kallisto). Nonetheless, Salmon is somehow easier to use., soo we will use Salmon in this pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use **Salmon** (documentation here: https://salmon.readthedocs.io/en/latest/index.html), two main steps are necessary:\n",
    "\n",
    "**1. build the ***gentrome*** index**:\n",
    "Gentrome is a contraction for genome and transcriptome. The `gentrome.fa` is a new hybrid fasta file which contains the decoy sequences from the genome, concatenated with the transcriptome, following the indications provided by the annotation file.\n",
    "\n",
    "The basic command to generate the index on the gentrome sequence is:\n",
    "<code> salmon index -t gentrome.fa.gz -i salmon_annot_index --gencode</code>\n",
    "\n",
    "**2. run pseudo-alignement of reads** :\n",
    "\n",
    "The generic command is:\n",
    "\n",
    "salmon quant -i <salmon_index> -l <lib_type> -1 <read_1.fastq> -2 <read_2.fastq> -o <output_dir>\n",
    "\n",
    "<code>salmon quant -i salmon_annot_index \\\n",
    "         -l A \\\n",
    "         -1 sampleID_R1_fastp.fastq.gz \\\n",
    "         -2 sampleID_R2_fastp.fastq.gz \\\n",
    "\t --validateMappings \\\n",
    "\t -o output_dir</code>\n",
    "     \n",
    "The main options above are:\n",
    "- `-i` : to specify the ngentrome index file\n",
    "- `-l` : to specify the library type with the argument `A` to let Salmon infer it, or manually specifying the orientation (I = inward, O = outward, M = matching), the strandedness (S = stranded, U = unstranded) and the strand from which the read originates in a strand-specific protocol (F = read 1 comes from the forward strand, R = read 1 comes from the reverse strand)\n",
    "\n",
    "Among other options that can be used, we higlight two of them:\n",
    "- `-p` : to specify the number of threads, we will use it.\n",
    "- `--numBootstraps` : to optionally compute bootstrapped abundance estimates. This is very time consuming as it is done by resampling (with replacement) from the counts assigned to the fragment equivalence classes, and then re-running the optimization procedure,for each such sample. It is used to assess technical variance in the main abundance estimates. The more samples computed, the better the estimates of variance, but the more computation (and time) required. We are not using it.\n",
    "\n",
    "\n",
    "\n",
    "For each sample, we obtain a folder in salmon _res_folder with `quant.sf` as main output. This file contains ***TPM (transcripts per million)*** and read count for each transcript ID in rows.\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">Caution, TPM are not integger values. It may have implications for downstream analyses.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 2.2- Step preparation\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We check the version of Salmon we are using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "salmon 1.10.2\n"
     ]
    }
   ],
   "source": [
    "## Code cell 20 ##\n",
    "\n",
    "salmon -v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We precise the folder where the Salmon pseudo-alignments will be saved:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The resulting salmon files will be in /shared/projects/2413_rnaseq_cea/scaburet/Results/salmon3/\n"
     ]
    }
   ],
   "source": [
    "## Code cell 21 ##\n",
    "\n",
    "salmonfolder=\"${gohome}$USER/Results/salmon3/\"\n",
    "mkdir -p ${salmonfolder}\n",
    "echo \"The resulting salmon files will be in ${salmonfolder}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "- and for Salmon pseudomapping, we will also need to generate a folder with the indexing of the transcripts, so we remember the path `Reference` including all reference sequences and annotations (we use the common file in the `alldata` folder):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The general folder for reference genome, annotations and index files is /shared/projects/2413_rnaseq_cea/alldata/Reference/\n",
      "The index folder for Salmon is /shared/projects/2413_rnaseq_cea/alldata/Reference//salmon/\n"
     ]
    }
   ],
   "source": [
    "## Code cell 22 ##\n",
    "\n",
    "reffolder=\"${gohome}alldata/Reference/\"\n",
    "# mkdir -p ${reffolder}\n",
    "echo \"The general folder for reference genome, annotations and index files is ${reffolder}\"\n",
    "\n",
    "\n",
    "salmonreffolder=\"${reffolder}/salmon/\"\n",
    "# mkdir -p ${salmonreffolder}\n",
    "echo \"The index folder for Salmon is ${salmonreffolder}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "- finally, for Salmon pseudomapping, we will also need to specify the path to our input files, i.e, the fastq files after fastp quality control:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The analysed fastp.fastq files are in /shared/projects/2413_rnaseq_cea/scaburet/Results/fastp/\n",
      "and they are:\n",
      "SRR12730409_1.fastp.fastq.gz\n",
      "SRR12730409_2.fastp.fastq.gz\n",
      "SRR12730409_fastp.html\n",
      "SRR12730409_fastp.json\n",
      "SRR12730410_1.fastp.fastq.gz\n",
      "SRR12730410_2.fastp.fastq.gz\n",
      "SRR12730410_fastp.html\n",
      "SRR12730410_fastp.json\n",
      "SRR12730411_1.fastp.fastq.gz\n",
      "SRR12730411_2.fastp.fastq.gz\n",
      "SRR12730411_fastp.html\n",
      "SRR12730411_fastp.json\n",
      "preformation\n"
     ]
    }
   ],
   "source": [
    "## Code cell 23 ##\n",
    "\n",
    "fastpfolder=\"${gohome}$USER/Results/fastp/\"\n",
    "echo \"The analysed fastp.fastq files are in ${fastpfolder}\"\n",
    "echo \"and they are:\"\n",
    "ls ${fastpfolder} | grep -v -e \"_removed\" \n",
    "\n",
    "#| wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- an of course, we do not forget the log file !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Screen output is redirected to /shared/projects/2413_rnaseq_cea/scaburet/Results/logfiles/Salmon3.log\n"
     ]
    }
   ],
   "source": [
    "## Code cell 24 ##\n",
    "\n",
    "logfile4=\"${logfolder}Salmon3.log\"\n",
    "echo \"Screen output is redirected to ${logfile4}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "### 2.3- Run Salmon\n",
    "---\n",
    "\n",
    "#### 2.3.1. Build the gentrome index\n",
    "\n",
    "\n",
    "To gain time and preserve space, we already performed this step and the results are available for eveyone in the alldata folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "- obtain the **transcriptome sequences**\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "tags": []
   },
   "source": [
    "## (Code cell 24) ##\n",
    "\n",
    "# For Mus musculus release M35 (latest,June 2024) on GRCm39:\n",
    "\n",
    "transcriptgzurl=\"https://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_mouse/release_M35/gencode.vM35.transcripts.fa.gz\"\n",
    "\n",
    "echo \"===== Transcript file retrieval ...\" >> ${logfile4}\n",
    "wget -P \"${reffolder}\" -N \"${transcriptgzurl}\"\n",
    "echo \"... done\" >> ${logfile4}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "tags": []
   },
   "source": [
    "## (Code cell 25) ##\n",
    "\n",
    "transcriptfile=\"${reffolder}gencode.vM35.transcripts.fa.gz\"\n",
    "\n",
    "echo \"The transcript reference files is ${transcriptfile}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "- obtain the **genome sequence** *(already done in Pipe 04)*"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "tags": []
   },
   "source": [
    "## (Code cell 26) ##\n",
    "\n",
    "# For Mus musculus release M35 (latest,June 2024) on GRCm39:\n",
    "fagzurl=\"https://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_mouse/release_M35/GRCm39.primary_assembly.genome.fa.gz\"\n",
    "\n",
    "echo \"===== Genome sequence retrieval ...\" >> ${logfile4}\n",
    "wget -P \"${reffolder}\" -N \"${fagzurl}\"\n",
    "echo \"... done\" >> ${logfile4}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "tags": []
   },
   "source": [
    "## (Code cell 27) ##\n",
    "\n",
    "fagzfile=\"${reffolder}GRCm39.primary_assembly.genome.fa.gz\"\n",
    "\n",
    "echo \"The genome reference file is ${fagzfile}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "- **concatenate transcript sequences and genome sequence** :"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "tags": []
   },
   "source": [
    "## (Code cell 28) ##\n",
    "\n",
    "gentromefile=\"${salmonreffolder}gentrome.fa.gz\"\n",
    "cat ${transcriptfile} ${fagzfile} > ${gentromefile}\n",
    "ls -la ${salmonreffolder}\n",
    "\n",
    "#cat gencode.vM35.transcripts.fa.gz GRCm39.primary_assembly.genome.fa.gz > gentrome.fa.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "- extract the **name of contigs of the genome sequence** (headers of fasta sequences)\n",
    "\n",
    "Salmon recommands to use a selective alignment with a decoy-aware transcriptome, to mitigate potential spurious mapping of reads that actually arise from some unannotated genomic locus that is sequence-similar to an annotated transcriptome. Thus, decoy sequences will improve the quality of the pseudomammping.\n",
    "\n",
    "There are actually two methods for generating decoyed sequences, as specified in the documentation of Salmon. Here we use the second one, meaning the entire genome of the organism is used as the decoy sequence."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "tags": []
   },
   "source": [
    "## (Code cell 29) ##\n",
    "\n",
    "decoy=\"${salmonreffolder}decoys.txt\"\n",
    "\n",
    "grep \"^>\" <(gunzip -c ${fagzfile}) | cut -d \" \" -f 1 > ${decoy}\n",
    "sed -i.bak -e 's/>//g' ${decoy}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "- **transcriptome indexation** with the basic command (for mouse genome version 39):\n",
    "\n",
    "We choose the kmer size of 31 as recommanded in Salmon documentation for reads of at least 75 bases."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "tags": []
   },
   "source": [
    "## (Code cell 30) ##\n",
    "\n",
    "salmonindex=\"${salmonreffolder}salmon_vM35_index\"\n",
    "\n",
    "salmon index -t ${gentromefile}  \\\n",
    "             -i ${salmonindex} \\ \n",
    "             --decoys ${decoy} \\\n",
    "             --gencode \\\n",
    "             -k 31 \\\n",
    "             -p 18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.1. Run the pseudoalignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Screen output is redirected to /shared/projects/2413_rnaseq_cea/scaburet/Results/logfiles/Salmon3.log\n",
      "before loop\n",
      "starting the loop with /shared/projects/2413_rnaseq_cea/scaburet/Results/fastp/SRR12730409_1.fastp.fastq.gz\n",
      "====== Processing sampleID: SRR12730409...\n",
      "Version Server Response: Not Found\n",
      "### salmon (selective-alignment-based) v1.10.2\n",
      "### [ program ] => salmon \n",
      "### [ command ] => quant \n",
      "### [ index ] => { /shared/projects/2413_rnaseq_cea/alldata/Reference//salmon/salmon_vM35_index }\n",
      "### [ libType ] => { A }\n",
      "### [ mates1 ] => { /shared/projects/2413_rnaseq_cea/scaburet/Results/fastp/SRR12730409_1.fastp.fastq.gz }\n",
      "### [ mates2 ] => { /shared/projects/2413_rnaseq_cea/scaburet/Results/fastp/SRR12730409_2.fastp.fastq.gz }\n",
      "### [ validateMappings ] => { }\n",
      "### [ threads ] => { 5 }\n",
      "### [ output ] => { /shared/projects/2413_rnaseq_cea/scaburet/Results/salmon3/SRR12730409 }\n",
      "Logs will be written to /shared/projects/2413_rnaseq_cea/scaburet/Results/salmon3/SRR12730409/logs\n",
      "[2024-06-24 12:36:41.169] [jointLog] [info] setting maxHashResizeThreads to 5\n",
      "[2024-06-24 12:36:41.169] [jointLog] [info] Fragment incompatibility prior below threshold.  Incompatible fragments will be ignored.\n",
      "[2024-06-24 12:36:41.169] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65\n",
      "[2024-06-24 12:36:41.169] [jointLog] [info] Setting consensusSlack to selective-alignment default of 0.35.\n",
      "[2024-06-24 12:36:41.169] [jointLog] [info] parsing read library format\n",
      "[2024-06-24 12:36:41.169] [jointLog] [info] There is 1 library.\n",
      "[2024-06-24 12:36:41.170] [jointLog] [info] Loading pufferfish index\n",
      "[2024-06-24 12:36:41.170] [jointLog] [info] Loading dense pufferfish index.\n",
      "-----------------------------------------\n",
      "| Loading contig table | Time = 24.62 s\n",
      "-----------------------------------------\n",
      "size = 25108302\n",
      "-----------------------------------------\n",
      "| Loading contig offsets | Time = 170.88 ms\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| Loading reference lengths | Time = 287.07 us\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| Loading mphf table | Time = 582.17 ms\n",
      "-----------------------------------------\n",
      "size = 3025387350\n",
      "Number of ones: 25108301\n",
      "Number of ones per inventory item: 512\n",
      "Inventory entries filled: 49040\n",
      "-----------------------------------------\n",
      "| Loading contig boundaries | Time = 6.4809 s\n",
      "-----------------------------------------\n",
      "size = 3025387350\n",
      "-----------------------------------------\n",
      "| Loading sequence | Time = 1.4129 s\n",
      "-----------------------------------------\n",
      "size = 2272138320\n",
      "-----------------------------------------\n",
      "| Loading positions | Time = 7.2517 s\n",
      "-----------------------------------------\n",
      "size = 2977721149\n",
      "-----------------------------------------\n",
      "| Loading reference sequence | Time = 1.0096 s\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| Loading reference accumulative lengths | Time = 22.522 ms\n",
      "-----------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[2024-06-24 12:37:22.724] [jointLog] [info] done\n",
      "[2024-06-24 12:37:22.759] [jointLog] [info] Index contained 147,617 targets\n",
      "[2024-06-24 12:37:22.796] [jointLog] [info] Number of decoys : 61\n",
      "[2024-06-24 12:37:22.796] [jointLog] [info] First decoy index : 147,519 \n",
      "[2024-06-24 12:37:23.800] [jointLog] [info] Automatically detected most likely library type as IU\n",
      "\n",
      "\u001b[A\u001b[32mprocessed\u001b[31m 500,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 1,144,944, hits per frag:  2.35273\u001b[A\u001b[32mprocessed\u001b[31m 1,000,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 2,266,748, hits per frag:  2.29719\u001b[A\u001b[32mprocessed\u001b[31m 1,500,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 3,380,834, hits per frag:  2.26755\u001b[A\u001b[32mprocessed\u001b[31m 2,000,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 4,461,153, hits per frag:  2.24127\u001b[A\u001b[32mprocessed\u001b[31m 2,500,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 5,586,534, hits per frag:  2.24388\u001b[A\u001b[32mprocessed\u001b[31m 3,000,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 6,710,738, hits per frag:  2.23739\u001b[A\u001b[32mprocessed\u001b[31m 3,500,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 7,789,559, hits per frag:  2.22748\u001b[A\u001b[32mprocessed\u001b[31m 4,000,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 8,927,830, hits per frag:  2.24136\u001b[A\u001b[32mprocessed\u001b[31m 4,500,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 10,081,272, hits per frag:  2.26983\u001b[A\u001b[32mprocessed\u001b[31m 5,000,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 11,212,599, hits per frag:  2.2453\u001b[A\u001b[32mprocessed\u001b[31m 5,500,001 \u001b[32mfragments\u001b[0m\n",
      "hits: 12,408,773, hits per frag:  2.26047\u001b[A\u001b[32mprocessed\u001b[31m 6,000,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 13,506,171, hits per frag:  2.25216\u001b[A\u001b[32mprocessed\u001b[31m 6,500,001 \u001b[32mfragments\u001b[0m\n",
      "hits: 14,633,852, hits per frag:  2.25788\u001b[A\u001b[32mprocessed\u001b[31m 7,000,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 15,731,043, hits per frag:  2.24841\u001b[A\u001b[32mprocessed\u001b[31m 7,500,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 16,861,090, hits per frag:  2.25331\u001b[A\u001b[32mprocessed\u001b[31m 8,000,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 17,939,113, hits per frag:  2.24336\u001b[A\u001b[32mprocessed\u001b[31m 8,500,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 19,070,537, hits per frag:  2.24683\u001b[A\u001b[32mprocessed\u001b[31m 9,000,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 20,204,693, hits per frag:  2.24581\u001b[A\u001b[32mprocessed\u001b[31m 9,500,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 21,313,321, hits per frag:  2.24779\u001b[A\u001b[32mprocessed\u001b[31m 10,000,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 22,427,079, hits per frag:  2.24393\u001b[A\u001b[32mprocessed\u001b[31m 10,500,001 \u001b[32mfragments\u001b[0m\n",
      "hits: 23,553,830, hits per frag:  2.24557\u001b[A\u001b[32mprocessed\u001b[31m 11,000,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 24,640,507, hits per frag:  2.24157\u001b[A\u001b[32mprocessed\u001b[31m 11,500,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 25,634,589, hits per frag:  2.23212\u001b[A\u001b[32mprocessed\u001b[31m 12,000,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 26,848,754, hits per frag:  2.23997\u001b[A\u001b[32mprocessed\u001b[31m 12,500,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 27,889,921, hits per frag:  2.23188\u001b[A\u001b[32mprocessed\u001b[31m 13,000,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 28,975,985, hits per frag:  2.23134\u001b[A\u001b[32mprocessed\u001b[31m 13,500,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 30,057,372, hits per frag:  2.22935\u001b[A\u001b[32mprocessed\u001b[31m 14,000,001 \u001b[32mfragments\u001b[0m\n",
      "hits: 31,220,303, hits per frag:  2.23108\u001b[A\u001b[32mprocessed\u001b[31m 14,500,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 32,335,496, hits per frag:  2.23135\u001b[A\u001b[32mprocessed\u001b[31m 15,000,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 33,411,666, hits per frag:  2.22842\u001b[A\u001b[32mprocessed\u001b[31m 15,500,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 34,495,700, hits per frag:  2.22593\u001b[A\u001b[32mprocessed\u001b[31m 16,000,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 35,575,008, hits per frag:  2.2278\u001b[A\u001b[32mprocessed\u001b[31m 16,500,001 \u001b[32mfragments\u001b[0m\n",
      "hits: 36,610,915, hits per frag:  2.22053\u001b[A\u001b[32mprocessed\u001b[31m 17,000,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 37,750,256, hits per frag:  2.22141\u001b[A\u001b[32mprocessed\u001b[31m 17,500,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 38,937,121, hits per frag:  2.22535\u001b[A\u001b[32mprocessed\u001b[31m 18,000,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 40,005,537, hits per frag:  2.22328\u001b[A\u001b[32mprocessed\u001b[31m 18,500,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 41,012,739, hits per frag:  2.21736\u001b[A\u001b[32mprocessed\u001b[31m 19,000,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 42,156,657, hits per frag:  2.22643\u001b[A\u001b[32mprocessed\u001b[31m 19,500,001 \u001b[32mfragments\u001b[0m\n",
      "hits: 43,249,607, hits per frag:  2.21811\u001b[A\u001b[32mprocessed\u001b[31m 20,000,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 44,325,074, hits per frag:  2.21893\u001b[A\u001b[32mprocessed\u001b[31m 20,500,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 45,362,959, hits per frag:  2.21451\u001b[A\u001b[32mprocessed\u001b[31m 21,000,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 46,349,391, hits per frag:  2.20741\u001b[A\u001b[32mprocessed\u001b[31m 21,500,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 47,382,571, hits per frag:  2.206\u001b[A\u001b[32mprocessed\u001b[31m 22,000,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 48,514,121, hits per frag:  2.20555\u001b[A\u001b[32mprocessed\u001b[31m 22,500,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 49,614,018, hits per frag:  2.20634\u001b[A\u001b[32mprocessed\u001b[31m 23,000,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 50,716,083, hits per frag:  2.20718\u001b[A\u001b[32mprocessed\u001b[31m 23,500,001 \u001b[32mfragments\u001b[0m\n",
      "hits: 51,709,500, hits per frag:  2.20046\u001b[A\u001b[32mprocessed\u001b[31m 24,000,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 52,769,544, hits per frag:  2.19965\u001b[A\u001b[32mprocessed\u001b[31m 24,500,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 53,664,675, hits per frag:  2.19051\u001b[A\u001b[32mprocessed\u001b[31m 25,000,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 54,602,611, hits per frag:  2.1856\u001b[A\u001b[32mprocessed\u001b[31m 25,500,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 55,571,274, hits per frag:  2.18117\u001b[A\u001b[32mprocessed\u001b[31m 26,000,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 56,520,710, hits per frag:  2.17432\u001b[A\u001b[32mprocessed\u001b[31m 26,500,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 57,652,781, hits per frag:  2.17624\u001b[A\u001b[32mprocessed\u001b[31m 27,000,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 58,806,039, hits per frag:  2.17849\u001b[A\u001b[32mprocessed\u001b[31m 27,500,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 59,928,360, hits per frag:  2.18191\u001b[A\u001b[32mprocessed\u001b[31m 28,000,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 61,129,583, hits per frag:  2.18466\u001b[A\u001b[32mprocessed\u001b[31m 28,500,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 62,243,034, hits per frag:  2.18428\u001b[A\u001b[32mprocessed\u001b[31m 29,000,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 63,367,043, hits per frag:  2.18534\u001b[A\u001b[32mprocessed\u001b[31m 29,500,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 64,321,709, hits per frag:  2.18122\u001b[A\u001b[32mprocessed\u001b[31m 30,000,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 65,435,162, hits per frag:  2.18991\u001b[A\u001b[32mprocessed\u001b[31m 30,500,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 66,447,597, hits per frag:  2.18383\u001b[A\u001b[32mprocessed\u001b[31m 31,000,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 67,573,404, hits per frag:  2.18064\u001b[A\u001b[32mprocessed\u001b[31m 31,500,001 \u001b[32mfragments\u001b[0m\n",
      "hits: 68,656,731, hits per frag:  2.17984\u001b[A\u001b[32mprocessed\u001b[31m 32,000,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 69,793,313, hits per frag:  2.1811\u001b[A\u001b[32mprocessed\u001b[31m 32,500,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 70,875,808, hits per frag:  2.18135\u001b[A\u001b[32mprocessed\u001b[31m 33,000,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 72,002,578, hits per frag:  2.18225\u001b[A\u001b[32mprocessed\u001b[31m 33,500,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 73,129,001, hits per frag:  2.18337\u001b[A\u001b[32mprocessed\u001b[31m 34,000,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 74,199,540, hits per frag:  2.1826\u001b[A\u001b[32mprocessed\u001b[31m 34,500,001 \u001b[32mfragments\u001b[0m\n",
      "hits: 75,211,996, hits per frag:  2.18048\u001b[A\u001b[32mprocessed\u001b[31m 35,000,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 76,328,675, hits per frag:  2.18212\u001b[A\u001b[32mprocessed\u001b[31m 35,500,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 77,454,661, hits per frag:  2.18248\u001b[A\u001b[32mprocessed\u001b[31m 36,000,001 \u001b[32mfragments\u001b[0m\n",
      "hits: 78,570,551, hits per frag:  2.18279\u001b[A\u001b[32mprocessed\u001b[31m 36,500,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 79,649,273, hits per frag:  2.1829\u001b[A\u001b[32mprocessed\u001b[31m 37,000,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 80,746,281, hits per frag:  2.18279\u001b[A\u001b[32mprocessed\u001b[31m 37,500,001 \u001b[32mfragments\u001b[0m\n",
      "hits: 81,793,435, hits per frag:  2.18178\u001b[A\u001b[32mprocessed\u001b[31m 38,000,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 82,844,562, hits per frag:  2.18088\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[2024-06-24 12:54:10.134] [jointLog] [info] Computed 344,985 rich equivalence classes for further processing\n",
      "[2024-06-24 12:54:10.134] [jointLog] [info] Counted 28,788,645 total reads in the equivalence classes \n",
      "[2024-06-24 12:54:10.138] [jointLog] [info] Number of mappings discarded because of alignment score : 69,021,761\n",
      "[2024-06-24 12:54:10.138] [jointLog] [info] Number of fragments entirely discarded because of alignment score : 7,160,477\n",
      "[2024-06-24 12:54:10.138] [jointLog] [info] Number of fragments discarded because they are best-mapped to decoys : 1,045,152\n",
      "[2024-06-24 12:54:10.138] [jointLog] [info] Number of fragments discarded because they have only dovetail (discordant) mappings to valid targets : 272,999\n",
      "[2024-06-24 12:54:10.138] [jointLog] [info] Mapping rate = 75.3482%\n",
      "\n",
      "[2024-06-24 12:54:10.138] [jointLog] [info] finished quantifyLibrary()\n",
      "[2024-06-24 12:54:10.139] [jointLog] [info] Starting optimizer\n",
      "[2024-06-24 12:54:10.251] [jointLog] [info] Marked 0 weighted equivalence classes as degenerate\n",
      "[2024-06-24 12:54:10.269] [jointLog] [info] iteration = 0 | max rel diff. = 8176.98\n",
      "[2024-06-24 12:54:11.931] [jointLog] [info] iteration = 100 | max rel diff. = 6.3087\n",
      "[2024-06-24 12:54:13.586] [jointLog] [info] iteration = 200 | max rel diff. = 11.7683\n",
      "[2024-06-24 12:54:15.247] [jointLog] [info] iteration = 300 | max rel diff. = 3.29462\n",
      "[2024-06-24 12:54:16.910] [jointLog] [info] iteration = 400 | max rel diff. = 1.06555\n",
      "[2024-06-24 12:54:18.563] [jointLog] [info] iteration = 500 | max rel diff. = 0.410904\n",
      "[2024-06-24 12:54:20.237] [jointLog] [info] iteration = 600 | max rel diff. = 0.335245\n",
      "[2024-06-24 12:54:21.895] [jointLog] [info] iteration = 700 | max rel diff. = 0.0833413\n",
      "[2024-06-24 12:54:23.594] [jointLog] [info] iteration = 800 | max rel diff. = 0.0419097\n",
      "[2024-06-24 12:54:25.287] [jointLog] [info] iteration = 900 | max rel diff. = 0.118118\n",
      "[2024-06-24 12:54:27.100] [jointLog] [info] iteration = 1,000 | max rel diff. = 0.0143686\n",
      "[2024-06-24 12:54:28.912] [jointLog] [info] iteration = 1,100 | max rel diff. = 0.0371958\n",
      "[2024-06-24 12:54:30.697] [jointLog] [info] iteration = 1,200 | max rel diff. = 0.0197795\n",
      "[2024-06-24 12:54:32.070] [jointLog] [info] iteration = 1,276 | max rel diff. = 0.00396481\n",
      "[2024-06-24 12:54:32.077] [jointLog] [info] Finished optimizer\n",
      "[2024-06-24 12:54:32.077] [jointLog] [info] writing output \n",
      "\n",
      "...done\n",
      "starting the loop with /shared/projects/2413_rnaseq_cea/scaburet/Results/fastp/SRR12730410_1.fastp.fastq.gz\n",
      "====== Processing sampleID: SRR12730410...\n",
      "Version Server Response: Not Found\n",
      "### salmon (selective-alignment-based) v1.10.2\n",
      "### [ program ] => salmon \n",
      "### [ command ] => quant \n",
      "### [ index ] => { /shared/projects/2413_rnaseq_cea/alldata/Reference//salmon/salmon_vM35_index }\n",
      "### [ libType ] => { A }\n",
      "### [ mates1 ] => { /shared/projects/2413_rnaseq_cea/scaburet/Results/fastp/SRR12730410_1.fastp.fastq.gz }\n",
      "### [ mates2 ] => { /shared/projects/2413_rnaseq_cea/scaburet/Results/fastp/SRR12730410_2.fastp.fastq.gz }\n",
      "### [ validateMappings ] => { }\n",
      "### [ threads ] => { 5 }\n",
      "### [ output ] => { /shared/projects/2413_rnaseq_cea/scaburet/Results/salmon3/SRR12730410 }\n",
      "Logs will be written to /shared/projects/2413_rnaseq_cea/scaburet/Results/salmon3/SRR12730410/logs\n",
      "[2024-06-24 12:54:34.842] [jointLog] [info] setting maxHashResizeThreads to 5\n",
      "[2024-06-24 12:54:34.842] [jointLog] [info] Fragment incompatibility prior below threshold.  Incompatible fragments will be ignored.\n",
      "[2024-06-24 12:54:34.842] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65\n",
      "[2024-06-24 12:54:34.842] [jointLog] [info] Setting consensusSlack to selective-alignment default of 0.35.\n",
      "[2024-06-24 12:54:34.842] [jointLog] [info] parsing read library format\n",
      "[2024-06-24 12:54:34.842] [jointLog] [info] There is 1 library.\n",
      "[2024-06-24 12:54:34.845] [jointLog] [info] Loading pufferfish index\n",
      "[2024-06-24 12:54:34.846] [jointLog] [info] Loading dense pufferfish index.\n",
      "-----------------------------------------\n",
      "| Loading contig table | Time = 24.761 s\n",
      "-----------------------------------------\n",
      "size = 25108302\n",
      "-----------------------------------------\n",
      "| Loading contig offsets | Time = 169.13 ms\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| Loading reference lengths | Time = 17.853 ms\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| Loading mphf table | Time = 668.29 ms\n",
      "-----------------------------------------\n",
      "size = 3025387350\n",
      "Number of ones: 25108301\n",
      "Number of ones per inventory item: 512\n",
      "Inventory entries filled: 49040\n",
      "-----------------------------------------\n",
      "| Loading contig boundaries | Time = 6.561 s\n",
      "-----------------------------------------\n",
      "size = 3025387350\n",
      "-----------------------------------------\n",
      "| Loading sequence | Time = 1.479 s\n",
      "-----------------------------------------\n",
      "size = 2272138320\n",
      "-----------------------------------------\n",
      "| Loading positions | Time = 12.961 s\n",
      "-----------------------------------------\n",
      "size = 2977721149\n",
      "-----------------------------------------\n",
      "| Loading reference sequence | Time = 1.2857 s\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| Loading reference accumulative lengths | Time = 845.02 us\n",
      "-----------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[2024-06-24 12:55:22.805] [jointLog] [info] done\n",
      "[2024-06-24 12:55:22.858] [jointLog] [info] Index contained 147,617 targets\n",
      "[2024-06-24 12:55:22.896] [jointLog] [info] Number of decoys : 61\n",
      "[2024-06-24 12:55:22.896] [jointLog] [info] First decoy index : 147,519 \n",
      "[2024-06-24 12:55:23.973] [jointLog] [info] Automatically detected most likely library type as IU\n",
      "\n",
      "\u001b[A\u001b[32mprocessed\u001b[31m 500,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 1,220,186, hits per frag:  2.53828\u001b[A\u001b[32mprocessed\u001b[31m 1,000,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 2,414,159, hits per frag:  2.43694\u001b[A\u001b[32mprocessed\u001b[31m 1,500,001 \u001b[32mfragments\u001b[0m\n",
      "hits: 3,571,263, hits per frag:  2.3936\u001b[A\u001b[32mprocessed\u001b[31m 2,000,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 4,739,018, hits per frag:  2.38182\u001b[A\u001b[32mprocessed\u001b[31m 2,500,001 \u001b[32mfragments\u001b[0m\n",
      "hits: 5,832,560, hits per frag:  2.34175\u001b[A\u001b[32mprocessed\u001b[31m 3,000,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 7,134,507, hits per frag:  2.38683\u001b[A\u001b[32mprocessed\u001b[31m 3,500,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 8,368,542, hits per frag:  2.39563\u001b[A\u001b[32mprocessed\u001b[31m 4,000,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 9,514,437, hits per frag:  2.38014\u001b[A\u001b[32mprocessed\u001b[31m 4,500,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 10,630,565, hits per frag:  2.3744\u001b[A\u001b[32mprocessed\u001b[31m 5,000,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 11,715,242, hits per frag:  2.35073\u001b[A\u001b[32mprocessed\u001b[31m 5,500,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 12,876,832, hits per frag:  2.34211\u001b[A\u001b[32mprocessed\u001b[31m 6,000,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 14,012,654, hits per frag:  2.34032\u001b[A\u001b[32mprocessed\u001b[31m 6,500,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 15,090,906, hits per frag:  2.3234\u001b[A\u001b[32mprocessed\u001b[31m 7,000,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 16,287,476, hits per frag:  2.3281\u001b[A\u001b[32mprocessed\u001b[31m 7,500,001 \u001b[32mfragments\u001b[0m\n",
      "hits: 17,486,475, hits per frag:  2.33352\u001b[A\u001b[32mprocessed\u001b[31m 8,000,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 18,573,563, hits per frag:  2.32825\u001b[A\u001b[32mprocessed\u001b[31m 8,500,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 19,682,777, hits per frag:  2.31676\u001b[A\u001b[32mprocessed\u001b[31m 9,000,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 20,937,811, hits per frag:  2.32648\u001b[A\u001b[32mprocessed\u001b[31m 9,500,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 22,066,289, hits per frag:  2.32401\u001b[A\u001b[32mprocessed\u001b[31m 10,000,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 23,218,361, hits per frag:  2.32359\u001b[A\u001b[32mprocessed\u001b[31m 10,500,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 24,424,446, hits per frag:  2.32802\u001b[A\u001b[32mprocessed\u001b[31m 11,000,001 \u001b[32mfragments\u001b[0m\n",
      "hits: 25,537,142, hits per frag:  2.32308\u001b[A\u001b[32mprocessed\u001b[31m 11,500,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 26,772,501, hits per frag:  2.3327\u001b[A\u001b[32mprocessed\u001b[31m 12,000,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 27,914,154, hits per frag:  2.32811\u001b[A\u001b[32mprocessed\u001b[31m 12,500,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 29,007,014, hits per frag:  2.32202\u001b[A\u001b[32mprocessed\u001b[31m 13,000,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 30,142,840, hits per frag:  2.32066\u001b[A\u001b[32mprocessed\u001b[31m 13,500,001 \u001b[32mfragments\u001b[0m\n",
      "hits: 31,290,977, hits per frag:  2.31908\u001b[A\u001b[32mprocessed\u001b[31m 14,000,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 32,389,329, hits per frag:  2.31454\u001b[A\u001b[32mprocessed\u001b[31m 14,500,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 33,655,649, hits per frag:  2.32119\u001b[A\u001b[32mprocessed\u001b[31m 15,000,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 34,733,087, hits per frag:  2.31798\u001b[A\u001b[32mprocessed\u001b[31m 15,500,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 35,899,394, hits per frag:  2.31659\u001b[A\u001b[32mprocessed\u001b[31m 16,000,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 36,991,682, hits per frag:  2.31225\u001b[A\u001b[32mprocessed\u001b[31m 16,500,001 \u001b[32mfragments\u001b[0m\n",
      "hits: 38,108,935, hits per frag:  2.31199\u001b[A\u001b[32mprocessed\u001b[31m 17,000,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 39,246,555, hits per frag:  2.31025\u001b[A\u001b[32mprocessed\u001b[31m 17,500,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 40,403,399, hits per frag:  2.31002\u001b[A\u001b[32mprocessed\u001b[31m 18,000,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 41,511,161, hits per frag:  2.30686\u001b[A\u001b[32mprocessed\u001b[31m 18,500,001 \u001b[32mfragments\u001b[0m\n",
      "hits: 42,664,247, hits per frag:  2.308\u001b[A\u001b[32mprocessed\u001b[31m 19,000,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 43,732,071, hits per frag:  2.30197\u001b[A\u001b[32mprocessed\u001b[31m 19,500,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 44,857,470, hits per frag:  2.30291\u001b[A\u001b[32mprocessed\u001b[31m 20,000,001 \u001b[32mfragments\u001b[0m\n",
      "hits: 45,943,054, hits per frag:  2.29753\u001b[A\u001b[32mprocessed\u001b[31m 20,500,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 47,080,173, hits per frag:  2.2973\u001b[A\u001b[32mprocessed\u001b[31m 21,000,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 48,174,643, hits per frag:  2.30225\u001b[A\u001b[32mprocessed\u001b[31m 21,500,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 49,443,703, hits per frag:  2.29975\u001b[A\u001b[32mprocessed\u001b[31m 22,000,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 50,610,087, hits per frag:  2.30118\u001b[A\u001b[32mprocessed\u001b[31m 22,500,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 51,514,621, hits per frag:  2.29086\u001b[A\u001b[32mprocessed\u001b[31m 23,000,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 52,649,300, hits per frag:  2.28933\u001b[A\u001b[32mprocessed\u001b[31m 23,500,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 53,773,718, hits per frag:  2.2894\u001b[A\u001b[32mprocessed\u001b[31m 24,000,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 54,880,012, hits per frag:  2.28754\u001b[A\u001b[32mprocessed\u001b[31m 24,500,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 55,872,746, hits per frag:  2.28085\u001b[A\u001b[32mprocessed\u001b[31m 25,000,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 57,005,774, hits per frag:  2.28139\u001b[A\u001b[32mprocessed\u001b[31m 25,500,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 58,199,006, hits per frag:  2.2836\u001b[A\u001b[32mprocessed\u001b[31m 26,000,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 59,385,170, hits per frag:  2.28535\u001b[A\u001b[32mprocessed\u001b[31m 26,500,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 60,551,629, hits per frag:  2.28512\u001b[A\u001b[32mprocessed\u001b[31m 27,000,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 61,738,800, hits per frag:  2.28671\u001b[A\u001b[32mprocessed\u001b[31m 27,500,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 62,721,433, hits per frag:  2.28173\u001b[A\u001b[32mprocessed\u001b[31m 28,000,001 \u001b[32mfragments\u001b[0m\n",
      "hits: 63,586,425, hits per frag:  2.27255\u001b[A\u001b[32mprocessed\u001b[31m 28,500,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 64,480,827, hits per frag:  2.26342\u001b[A\u001b[32mprocessed\u001b[31m 29,000,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 65,369,650, hits per frag:  2.25426\u001b[A\u001b[32mprocessed\u001b[31m 29,500,001 \u001b[32mfragments\u001b[0m\n",
      "hits: 66,410,470, hits per frag:  2.25256\u001b[A\u001b[32mprocessed\u001b[31m 30,000,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 67,661,931, hits per frag:  2.25649\u001b[A\u001b[32mprocessed\u001b[31m 30,500,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 68,724,393, hits per frag:  2.25365\u001b[A\u001b[32mprocessed\u001b[31m 31,000,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 69,858,692, hits per frag:  2.25354\u001b[A\u001b[32mprocessed\u001b[31m 31,500,001 \u001b[32mfragments\u001b[0m\n",
      "hits: 71,059,504, hits per frag:  2.2564\u001b[A\u001b[32mprocessed\u001b[31m 32,000,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 71,952,315, hits per frag:  2.24947\u001b[A\u001b[32mprocessed\u001b[31m 32,500,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 73,042,163, hits per frag:  2.24838\u001b[A\u001b[32mprocessed\u001b[31m 33,000,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 74,180,624, hits per frag:  2.24864\u001b[A\u001b[32mprocessed\u001b[31m 33,500,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 75,224,613, hits per frag:  2.2458\u001b[A\u001b[32mprocessed\u001b[31m 34,000,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 76,382,644, hits per frag:  2.2472\u001b[A\u001b[32mprocessed\u001b[31m 34,500,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 77,507,520, hits per frag:  2.24931\u001b[A\u001b[32mprocessed\u001b[31m 35,000,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 78,649,986, hits per frag:  2.24783\u001b[A\u001b[32mprocessed\u001b[31m 35,500,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 79,815,673, hits per frag:  2.2492\u001b[A\u001b[32mprocessed\u001b[31m 36,000,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 80,991,580, hits per frag:  2.25165\u001b[A\u001b[32mprocessed\u001b[31m 36,500,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 82,021,023, hits per frag:  2.25001\u001b[A\u001b[32mprocessed\u001b[31m 37,000,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 83,179,772, hits per frag:  2.25498\u001b[A\u001b[32mprocessed\u001b[31m 37,500,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 84,274,757, hits per frag:  2.24764\u001b[A\u001b[32mprocessed\u001b[31m 38,000,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 85,448,502, hits per frag:  2.24934\u001b[A\u001b[32mprocessed\u001b[31m 38,500,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 86,553,220, hits per frag:  2.24846\u001b[A\u001b[32mprocessed\u001b[31m 39,000,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 87,628,300, hits per frag:  2.24694\u001b[A\u001b[32mprocessed\u001b[31m 39,500,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 88,753,232, hits per frag:  2.24704\u001b[A\u001b[32mprocessed\u001b[31m 40,000,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 89,980,965, hits per frag:  2.25316\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[2024-06-24 13:12:25.832] [jointLog] [info] Computed 339,324 rich equivalence classes for further processing\n",
      "[2024-06-24 13:12:25.832] [jointLog] [info] Counted 30,713,106 total reads in the equivalence classes \n",
      "[2024-06-24 13:12:25.837] [jointLog] [info] Number of mappings discarded because of alignment score : 77,170,175\n",
      "[2024-06-24 13:12:25.837] [jointLog] [info] Number of fragments entirely discarded because of alignment score : 7,351,838\n",
      "[2024-06-24 13:12:25.837] [jointLog] [info] Number of fragments discarded because they are best-mapped to decoys : 1,030,557\n",
      "[2024-06-24 13:12:25.837] [jointLog] [info] Number of fragments discarded because they have only dovetail (discordant) mappings to valid targets : 313,649\n",
      "[2024-06-24 13:12:25.837] [jointLog] [info] Mapping rate = 76.5155%\n",
      "\n",
      "[2024-06-24 13:12:25.837] [jointLog] [info] finished quantifyLibrary()\n",
      "[2024-06-24 13:12:25.839] [jointLog] [info] Starting optimizer\n",
      "[2024-06-24 13:12:25.972] [jointLog] [info] Marked 0 weighted equivalence classes as degenerate\n",
      "[2024-06-24 13:12:25.990] [jointLog] [info] iteration = 0 | max rel diff. = 8015.06\n",
      "[2024-06-24 13:12:27.691] [jointLog] [info] iteration = 100 | max rel diff. = 17.9608\n",
      "[2024-06-24 13:12:29.397] [jointLog] [info] iteration = 200 | max rel diff. = 1.80958\n",
      "[2024-06-24 13:12:31.073] [jointLog] [info] iteration = 300 | max rel diff. = 10.8713\n",
      "[2024-06-24 13:12:32.760] [jointLog] [info] iteration = 400 | max rel diff. = 2.40825\n",
      "[2024-06-24 13:12:34.446] [jointLog] [info] iteration = 500 | max rel diff. = 0.180194\n",
      "[2024-06-24 13:12:36.224] [jointLog] [info] iteration = 600 | max rel diff. = 0.807537\n",
      "[2024-06-24 13:12:37.947] [jointLog] [info] iteration = 700 | max rel diff. = 0.0288658\n",
      "[2024-06-24 13:12:39.620] [jointLog] [info] iteration = 800 | max rel diff. = 0.0558125\n",
      "[2024-06-24 13:12:41.326] [jointLog] [info] iteration = 900 | max rel diff. = 0.0556426\n",
      "[2024-06-24 13:12:43.017] [jointLog] [info] iteration = 1,000 | max rel diff. = 0.0346065\n",
      "[2024-06-24 13:12:44.757] [jointLog] [info] iteration = 1,100 | max rel diff. = 0.0273649\n",
      "[2024-06-24 13:12:46.460] [jointLog] [info] iteration = 1,200 | max rel diff. = 0.101519\n",
      "[2024-06-24 13:12:48.158] [jointLog] [info] iteration = 1,300 | max rel diff. = 0.0364317\n",
      "[2024-06-24 13:12:49.934] [jointLog] [info] iteration = 1,400 | max rel diff. = 0.135698\n",
      "[2024-06-24 13:12:51.622] [jointLog] [info] iteration = 1,500 | max rel diff. = 0.0266392\n",
      "[2024-06-24 13:12:52.270] [jointLog] [info] iteration = 1,538 | max rel diff. = 0.00430646\n",
      "[2024-06-24 13:12:52.276] [jointLog] [info] Finished optimizer\n",
      "[2024-06-24 13:12:52.276] [jointLog] [info] writing output \n",
      "\n",
      "...done\n",
      "starting the loop with /shared/projects/2413_rnaseq_cea/scaburet/Results/fastp/SRR12730411_1.fastp.fastq.gz\n",
      "====== Processing sampleID: SRR12730411...\n",
      "Version Server Response: Not Found\n",
      "### salmon (selective-alignment-based) v1.10.2\n",
      "### [ program ] => salmon \n",
      "### [ command ] => quant \n",
      "### [ index ] => { /shared/projects/2413_rnaseq_cea/alldata/Reference//salmon/salmon_vM35_index }\n",
      "### [ libType ] => { A }\n",
      "### [ mates1 ] => { /shared/projects/2413_rnaseq_cea/scaburet/Results/fastp/SRR12730411_1.fastp.fastq.gz }\n",
      "### [ mates2 ] => { /shared/projects/2413_rnaseq_cea/scaburet/Results/fastp/SRR12730411_2.fastp.fastq.gz }\n",
      "### [ validateMappings ] => { }\n",
      "### [ threads ] => { 5 }\n",
      "### [ output ] => { /shared/projects/2413_rnaseq_cea/scaburet/Results/salmon3/SRR12730411 }\n",
      "Logs will be written to /shared/projects/2413_rnaseq_cea/scaburet/Results/salmon3/SRR12730411/logs\n",
      "[2024-06-24 13:12:54.853] [jointLog] [info] setting maxHashResizeThreads to 5\n",
      "[2024-06-24 13:12:54.853] [jointLog] [info] Fragment incompatibility prior below threshold.  Incompatible fragments will be ignored.\n",
      "[2024-06-24 13:12:54.853] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65\n",
      "[2024-06-24 13:12:54.853] [jointLog] [info] Setting consensusSlack to selective-alignment default of 0.35.\n",
      "[2024-06-24 13:12:54.853] [jointLog] [info] parsing read library format\n",
      "[2024-06-24 13:12:54.853] [jointLog] [info] There is 1 library.\n",
      "[2024-06-24 13:12:54.855] [jointLog] [info] Loading pufferfish index\n",
      "[2024-06-24 13:12:54.855] [jointLog] [info] Loading dense pufferfish index.\n",
      "-----------------------------------------\n",
      "| Loading contig table | Time = 25.422 s\n",
      "-----------------------------------------\n",
      "size = 25108302\n",
      "-----------------------------------------\n",
      "| Loading contig offsets | Time = 85.216 ms\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| Loading reference lengths | Time = 272.99 us\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| Loading mphf table | Time = 2.3354 s\n",
      "-----------------------------------------\n",
      "size = 3025387350\n",
      "Number of ones: 25108301\n",
      "Number of ones per inventory item: 512\n",
      "Inventory entries filled: 49040\n",
      "-----------------------------------------\n",
      "| Loading contig boundaries | Time = 7.2005 s\n",
      "-----------------------------------------\n",
      "size = 3025387350\n",
      "-----------------------------------------\n",
      "| Loading sequence | Time = 1.0601 s\n",
      "-----------------------------------------\n",
      "size = 2272138320\n",
      "-----------------------------------------\n",
      "| Loading positions | Time = 19.439 s\n",
      "-----------------------------------------\n",
      "size = 2977721149\n",
      "-----------------------------------------\n",
      "| Loading reference sequence | Time = 561.92 ms\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| Loading reference accumulative lengths | Time = 923.26 us\n",
      "-----------------------------------------\n",
      "[2024-06-24 13:13:50.963] [jointLog] [info] done\n",
      "[2024-06-24 13:13:51.021] [jointLog] [info] Index contained 147,617 targets\n",
      "[2024-06-24 13:13:51.060] [jointLog] [info] Number of decoys : 61\n",
      "[2024-06-24 13:13:51.060] [jointLog] [info] First decoy index : 147,519 \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[2024-06-24 13:13:51.999] [jointLog] [info] Automatically detected most likely library type as IU\n",
      "\n",
      "\u001b[A\u001b[32mprocessed\u001b[31m 500,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 1,048,775, hits per frag:  2.20508\u001b[A\u001b[32mprocessed\u001b[31m 1,000,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 2,143,710, hits per frag:  2.17434\u001b[A\u001b[32mprocessed\u001b[31m 1,500,001 \u001b[32mfragments\u001b[0m\n",
      "hits: 3,205,358, hits per frag:  2.14098\u001b[A\u001b[32mprocessed\u001b[31m 2,000,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 4,346,365, hits per frag:  2.17641\u001b[A\u001b[32mprocessed\u001b[31m 2,500,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 5,487,310, hits per frag:  2.20223\u001b[A\u001b[32mprocessed\u001b[31m 3,000,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 6,642,515, hits per frag:  2.22852\u001b[A\u001b[32mprocessed\u001b[31m 3,500,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 7,658,428, hits per frag:  2.22189\u001b[A\u001b[32mprocessed\u001b[31m 4,000,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 8,785,216, hits per frag:  2.19778\u001b[A\u001b[32mprocessed\u001b[31m 4,500,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 9,853,670, hits per frag:  2.19069\u001b[A\u001b[32mprocessed\u001b[31m 5,000,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 10,903,578, hits per frag:  2.18238\u001b[A\u001b[32mprocessed\u001b[31m 5,500,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 12,062,323, hits per frag:  2.2004\u001b[A\u001b[32mprocessed\u001b[31m 6,000,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 13,099,056, hits per frag:  2.18923\u001b[A\u001b[32mprocessed\u001b[31m 6,500,001 \u001b[32mfragments\u001b[0m\n",
      "hits: 14,185,031, hits per frag:  2.1892\u001b[A\u001b[32mprocessed\u001b[31m 7,000,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 15,266,477, hits per frag:  2.19918\u001b[A\u001b[32mprocessed\u001b[31m 7,500,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 16,382,984, hits per frag:  2.18521\u001b[A\u001b[32mprocessed\u001b[31m 8,000,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 17,401,441, hits per frag:  2.18022\u001b[A\u001b[32mprocessed\u001b[31m 8,500,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 18,469,337, hits per frag:  2.18607\u001b[A\u001b[32mprocessed\u001b[31m 9,000,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 19,519,521, hits per frag:  2.16998\u001b[A\u001b[32mprocessed\u001b[31m 9,500,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 20,667,350, hits per frag:  2.177\u001b[A\u001b[32mprocessed\u001b[31m 10,000,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 21,734,759, hits per frag:  2.18029\u001b[A\u001b[32mprocessed\u001b[31m 10,500,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 22,826,333, hits per frag:  2.1782\u001b[A\u001b[32mprocessed\u001b[31m 11,000,001 \u001b[32mfragments\u001b[0m\n",
      "hits: 23,966,391, hits per frag:  2.18181\u001b[A\u001b[32mprocessed\u001b[31m 11,500,001 \u001b[32mfragments\u001b[0m\n",
      "hits: 25,018,235, hits per frag:  2.1779\u001b[A\u001b[32mprocessed\u001b[31m 12,000,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 26,105,301, hits per frag:  2.17644\u001b[A\u001b[32mprocessed\u001b[31m 12,500,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 27,143,838, hits per frag:  2.17345\u001b[A\u001b[32mprocessed\u001b[31m 13,000,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 28,134,119, hits per frag:  2.17052\u001b[A\u001b[32mprocessed\u001b[31m 13,500,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 29,161,598, hits per frag:  2.16037\u001b[A\u001b[32mprocessed\u001b[31m 14,000,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 30,205,655, hits per frag:  2.15816\u001b[A\u001b[32mprocessed\u001b[31m 14,500,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 31,301,829, hits per frag:  2.16011\u001b[A\u001b[32mprocessed\u001b[31m 15,000,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 32,370,192, hits per frag:  2.15924\u001b[A\u001b[32mprocessed\u001b[31m 15,500,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 33,476,795, hits per frag:  2.16038\u001b[A\u001b[32mprocessed\u001b[31m 16,000,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 34,566,296, hits per frag:  2.16084\u001b[A\u001b[32mprocessed\u001b[31m 16,500,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 35,676,653, hits per frag:  2.16274\u001b[A\u001b[32mprocessed\u001b[31m 17,000,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 36,771,291, hits per frag:  2.16491\u001b[A\u001b[32mprocessed\u001b[31m 17,500,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 37,857,781, hits per frag:  2.16348\u001b[A\u001b[32mprocessed\u001b[31m 18,000,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 38,901,149, hits per frag:  2.16218\u001b[A\u001b[32mprocessed\u001b[31m 18,500,001 \u001b[32mfragments\u001b[0m\n",
      "hits: 39,982,639, hits per frag:  2.16199\u001b[A\u001b[32mprocessed\u001b[31m 19,000,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 41,049,991, hits per frag:  2.16221\u001b[A\u001b[32mprocessed\u001b[31m 19,500,000 \u001b[32mfragments\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "## Code cell 31 ##\n",
    "\n",
    "echo \"Screen output is redirected to ${logfile4}\"\n",
    "\n",
    "# as time command does not redirect output\n",
    "echo \"operation starts at $(date)\" >> ${logfile4}\n",
    "echo \"before loop\"\n",
    "\n",
    "time for read1 in $(ls \"${gohome}$USER/Results/fastp/\"*_1.fastp.fastq.gz); do\n",
    "    echo \"starting the loop with ${read1}\"\n",
    "    \n",
    "    # handling names with the sample name\n",
    "    samplenum=$(basename ${read1} | cut -d\"_\" -f1)\n",
    "    echo \"====== Processing sampleID: ${samplenum}...\" | tee -a ${logfile4}\n",
    "    read2=$(echo ${read1} | sed 's#_1#_2#')\n",
    "\n",
    "    echo \"Salmon starts at $(date)\" >> ${logfile4}\n",
    "    \n",
    "    # Salmon working\n",
    "    salmon quant -i \"${salmonreffolder}salmon_vM35_index\" -l A \\\n",
    "         -1 ${read1} \\\n",
    "         -2 ${read2} \\\n",
    "         --validateMappings \\\n",
    "         --threads ${authorizedCPU} -o \"${salmonfolder}${samplenum}\" \\\n",
    "         |& tee -a ${logfile4}\n",
    "         \n",
    "    echo \"Salmon ends at $(date)\" >> ${logfile4}\n",
    "    \n",
    "    echo \"...done\" | tee -a ${logfile4} \n",
    "done  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "For more details, you can follow a nice tutorial here: https://combine-lab.github.io/alevin-tutorial/2019/selective-alignment/ or this one: https://combine-lab.github.io/salmon/getting_started/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "## 3 - MultiQC on featureCounts and Salmon\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3.1 - Folder, filename, title and comment**\n",
    "\n",
    "Let's indicate where report files are to be placed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code cell 39 ## \n",
    "\n",
    "qcsummaries=\"${gohome}$USER/Results/multiqc/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We specify then names for files and title to display on html report page. <a id=\"multiqctextvar2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code cell 40 ## \n",
    "\n",
    "inamemyfile=\"5_featureCounts_salmon_3samples\"\n",
    "\n",
    "mytitle=$(echo \"Quality check after featureCounts and Salmon\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To keep record of what have been done with these files, we add an comment to remember for later use and for informing others readers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code cell 41 ## \n",
    "\n",
    "mycomment=$(echo \"featureCounts run at gene level and Salmon for pseudomapping on transcripts using the mouse genome (GRCm39), version M35 (Ensembl 112)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3.2 - Generate summary report**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code cell 42 ## \n",
    "\n",
    "logfile5=\"${logfolder}multiqc-featurecounts-salmon.log\"\n",
    "echo \"Screen output is also saved in ${logfile5}\"\n",
    "\n",
    "echo \"operation starting by $(date)\" >> ${logfile5}\n",
    "multiqc --interactive --export \\\n",
    "        --module featureCounts ${featcountfolder} \\\n",
    "        --module salmon ${salmonfolder} \\\n",
    "        --outdir \"$qcsummaries\" \\\n",
    "        --filename \"${inamemyfile}\" \\\n",
    "        --title \"${mytitle}\"  \\\n",
    "        --comment \"${mycomment}\" \\\n",
    "        \"${gohome}$USER/Results/\" \\\n",
    "        |& tee -a ${logfile}\n",
    "echo \"operation finished by $(date)\" >> ${logfile5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code cell 43 ## \n",
    "\n",
    "# to see which files we have afterward and follow folder sizes\n",
    "ls -lh \"${qcsummaries}\" >> ${logfile}\n",
    "ls -lh \"${gohome}$USER/Results/\" >> ${logfile}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "## 4 - Monitoring disk usage\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code cell 44 ##\n",
    "\n",
    "du -h -d2 ${gohome}$USER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a personal folder that gets too heavy.  Let's remove some files we won't use anymore: \n",
    "\n",
    "- initial srr files in Data/sra/   \n",
    "- raw fastq.gz files in Data/fastq/raw/   \n",
    "- cleaned fastq.gz files in /Results/fastp   \n",
    "- intermediate Aligned.sortedByNames.bam files produced by <code>samtools</code> for <code>featuresCounts</code> above, if the rm command was masked at the end of Code cell 12.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code cell 45 ##\n",
    "\n",
    "# Saving disk space\n",
    "\n",
    "# Removing:\n",
    "# initial srr files\n",
    "rm -r ${gohome}$USER/Data/sra/\n",
    "\n",
    "# raw fastq.gz\n",
    "rm ${gohome}$USER/Data/fastq/raw/*.fastq.gz\n",
    "\n",
    "# cleaned fastq.gz\n",
    "#rm ${gohome}$USER/Results/fastp/*.fastp.fastq.gz\n",
    "\n",
    "# intermediate Aligned.sortedByNames.bam\n",
    "# rm ${gohome}$USER/Results/featurecounts/*_Aligned.sortedByNames.bam    # if is was not already done in cell 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see our disk usage now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code cell 46 ##\n",
    "\n",
    "du -h -d2 ${gohome}$USER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "___\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "\n",
    "**Next Practical session**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we go on with an introduction to the R language, that will be used during the next steps of the analysis.  \n",
    "  \n",
    "**=> Step 7: Introduction to R** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "The jupyter notebook used for the next session will be *Pipe_07-R403_Intro-to-R.ipynb*    \n",
    "Let's retrieve it in our personal directory, in order to have a private copy to work on:   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Code cell 47 ##   \n",
    "\n",
    "cp \"${gohome}pipeline/Pipe_07a-R_intro-to-R.ipynb\" \"${gohome}$USER/\"\n",
    "cp \"${gohome}alldata/Example_Data/Temperatures.txt\" \"${gohome}$USER/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Save executed notebook**\n",
    "\n",
    "To end the session, save your executed notebook in your `run_notebooks` folder. Adjust the name with yours and reformat as Code cell to run it."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Code cell 48 ##   \n",
    "#mkdir -p /shared/projects/2413_rnaseq_cea/$USER/run_notebooks\n",
    "cp /shared/projects/2413_rnaseq_cea/$USER/Pipe_06-bash_reads-counts-and-pseudomapping.ipynb /shared/projects/2413_rnaseq_cea/$USER/run_notebooks/Pipe_06-bash_reads-counts-pseudomapping-run.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-success\"><b>Success:</b> Well done! You now know how to count reads per features.<br>\n",
    "Don't forget to save you notebook and export a copy as an <b>html</b> file as well <br>\n",
    "- Open \"File\" in the Menu<br>\n",
    "- Select \"Export Notebook As\"<br>\n",
    "- Export notebook as HTML<br>\n",
    "- You can then open it in your browser even without being connected to the server! \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Useful commands\n",
    "<div class=\"alert alert-block alert-info\"> \n",
    "    \n",
    "- <kbd>CTRL</kbd>+<kbd>S</kbd> : save notebook<br>    \n",
    "- <kbd>CTRL</kbd>+<kbd>ENTER</kbd> : Run Cell<br>  \n",
    "- <kbd>SHIFT</kbd>+<kbd>ENTER</kbd> : Run Cell and Select Next<br>   \n",
    "- <kbd>ALT</kbd>+<kbd>ENTER</kbd> : Run Cell and Insert Below<br>   \n",
    "- <kbd>ESC</kbd>+<kbd>y</kbd> : Change to *Code* Cell Type<br>  \n",
    "- <kbd>ESC</kbd>+<kbd>m</kbd> : Change to *Markdown* Cell Type<br> \n",
    "- <kbd>ESC</kbd>+<kbd>r</kbd> : Change to *Raw* Cell Type<br>    \n",
    "- <kbd>ESC</kbd>+<kbd>a</kbd> : Create Cell Above<br> \n",
    "- <kbd>ESC</kbd>+<kbd>b</kbd> : Create Cell Below<br> \n",
    "\n",
    "<em>  \n",
    "To make nice html reports with markdown: <a href=\"https://dillinger.io/\" title=\"dillinger.io\">html visualization tool 1</a> or <a href=\"https://stackedit.io/app#\" title=\"stackedit.io\">html visualization tool 2</a>, <a href=\"https://www.tablesgenerator.com/markdown_tables\" title=\"tablesgenerator.com\">to draw nice tables</a>, and the <a href=\"https://medium.com/analytics-vidhya/the-ultimate-markdown-guide-for-jupyter-notebook-d5e5abf728fd\" title=\"Ultimate guide\">Ultimate guide</a>. <br>\n",
    "Further reading on JupyterLab notebooks: <a href=\"https://jupyterlab.readthedocs.io/en/latest/user/notebook.html\" title=\"Jupyter Lab\">Jupyter Lab documentation</a>.<br>   \n",
    "</em>    \n",
    " \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "BÃ©nÃ©dicte Noblet - 05-07 2021   \n",
    "Sandrine Caburet - 02-05 2023   \n",
    "Claire Vandiedonck - 03-06 2023  \n",
    "Maj 16/06/2024 by @CVandiedonck"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  },
  "toc-showcode": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
